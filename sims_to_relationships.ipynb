{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Once we get the simulations generated in a folder, each of the folders will contain trackrefiner folder under which we have the different simulations generated for different parameters. This code will copy the trackrefiner data into a new directory retaining its structure, and this will have our final data for node features. Additionally it also generates the object relationships file for every simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import os, shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/Users/sushmadhamodharan/Downloads/CSV_Files\"\n",
    "\n",
    "# Collect files starting with \"Trackrefiner\"\n",
    "matching_files = []\n",
    "for root, _, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.startswith(\"Trackrefiner\"):\n",
    "            matching_files.append(os.path.join(root, file))\n",
    "\n",
    "destination_directory = Path(\"/Users/sushmadhamodharan/Downloads/finaldata\")\n",
    "if not destination_directory.exists():\n",
    "    destination_directory.mkdir()\n",
    "    \n",
    "[(destination_directory / i).mkdir() for i in np.unique(list(map(lambda x: x[45:57], matching_files))) if not (destination_directory / i).exists()]\n",
    "    \n",
    "for file in matching_files:\n",
    "    shutil.copy(file, destination_directory / file[45:57] / file.split(\"Trackrefiner/\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating parent child relationship\n",
    "def generate_parentdf(df):\n",
    "    parentdf = df[[\"stepNum\", \"ObjectNumber\", \"TrackObjects_ParentImageNumber_50\", \"TrackObjects_ParentObjectNumber_50\"]].copy(deep=True)\n",
    "    parentdf['Relationship'] = 'Parent'\n",
    "    parentdf.columns = [\"First Image Number\", \"First Object Number\", \"Second Image Number\", \"Second Object Number\", \"Relationship\"]\n",
    "    parentdf = parentdf[[\"Relationship\", \"First Image Number\", \"First Object Number\", \"Second Image Number\", \"Second Object Number\"]].copy(deep=True)\n",
    "    return parentdf\n",
    "\n",
    "#Generating neighbor relationship\n",
    "def compute_distance(position1, position2):\n",
    "    \n",
    "    distance = torch.norm(position1 - position2, dim=0)\n",
    "    return distance\n",
    "\n",
    "def generate_neighbor_df(df):\n",
    "    distance_threshold = 1.0\n",
    "    neighbordf = df[[\"stepNum\", \"ObjectNumber\", \"pos\"]].copy(deep=True)\n",
    "    edge_list = []\n",
    "    for timestep in range(1, df.stepNum.max()):\n",
    "        cells = neighbordf[neighbordf[\"stepNum\"]== timestep].iloc[:, 1:].values\n",
    "\n",
    "        for ix1, cell1 in enumerate(cells):\n",
    "            for ix2, cell2 in enumerate(cells[(ix1+1):]):\n",
    "                if compute_distance(cell1[1], cell2[1]) < distance_threshold:\n",
    "                    edge_list.append([\"Neighbors\", timestep, cell1[0], timestep, cell2[0]])\n",
    "                    \n",
    "    ngdf = pd.DataFrame(edge_list, columns = [\"Relationship\", \"First Image Number\", \"First Object Number\", \"Second Image Number\", \"Second Object Number\"])\n",
    "    return ngdf\n",
    "\n",
    "def generate_fulldf(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df['pos'] = df['pos'].apply(eval).apply(lambda x: torch.tensor(x, dtype = torch.float32))\n",
    "    reldf = pd.concat([generate_parentdf(df), generate_neighbor_df(df)])\n",
    "    return reldf\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_files = []\n",
    "for root, _, files in os.walk(destination_directory):\n",
    "    for file in files:\n",
    "        if file.startswith(\"Trackrefiner\"):\n",
    "            matching_files.append(os.path.join(root, file))\n",
    "            \n",
    "for file in matching_files:\n",
    "    generate_fulldf(file).to_csv(file.split(\"Trackrefiner\")[0] + \"ObjectRelationship.Trackrefiner\" + file.split(\"Trackrefiner\")[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
